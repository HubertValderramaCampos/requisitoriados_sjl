#!/usr/bin/env python3
"""
Sistema de Entrenamiento de Reconocimiento Facial Robusto
Usando DeepFace con modelos ArcFace/Facenet512
Extremadamente resistente a cambios de iluminaciÃ³n, pose, ruido, etc.
"""

import os
import json
import cv2
import numpy as np
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Tuple
from deepface import DeepFace
from tqdm import tqdm

# ConfiguraciÃ³n
MODEL_NAME = "Facenet512"  # Opciones: VGG-Face, Facenet, Facenet512, OpenFace, DeepFace, DeepID, ArcFace, Dlib, SFace
DETECTOR_BACKEND = "opencv"  # Opciones: opencv, ssd, dlib, mtcnn, retinaface, mediapipe
OUTPUT_DIR = Path("public/trained-faces")
PHOTOS_DIR = Path("training_photos")

class FaceTrainer:
    def __init__(self, person_name: str):
        self.person_name = person_name
        self.embeddings = []
        self.valid_photos = []
        self.failed_photos = []

        # Crear directorios
        OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
        PHOTOS_DIR.mkdir(parents=True, exist_ok=True)

    def capture_from_webcam(self, num_photos: int = 20) -> None:
        """
        Captura fotos desde la webcam con guÃ­as visuales
        """
        print(f"\nğŸ¥ Iniciando captura de {num_photos} fotos desde webcam...")
        print("ğŸ“¸ Instrucciones:")
        print("   - Presiona ESPACIO para capturar una foto")
        print("   - Presiona 'q' para salir")
        print("   - VarÃ­a tu expresiÃ³n, Ã¡ngulo e iluminaciÃ³n entre capturas\n")

        cap = cv2.VideoCapture(0)

        if not cap.isOpened():
            raise Exception("No se pudo abrir la webcam")

        captured = 0
        photo_paths = []

        while captured < num_photos:
            ret, frame = cap.read()
            if not ret:
                continue

            # Detectar rostro en tiempo real
            try:
                faces = DeepFace.extract_faces(
                    img_path=frame,
                    detector_backend=DETECTOR_BACKEND,
                    enforce_detection=False
                )

                # Dibujar rectÃ¡ngulo alrededor del rostro
                if faces:
                    for face_obj in faces:
                        facial_area = face_obj['facial_area']
                        x, y, w, h = facial_area['x'], facial_area['y'], facial_area['w'], facial_area['h']

                        # RectÃ¡ngulo verde si detecta rostro
                        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)
                        cv2.putText(frame, "Rostro Detectado", (x, y-10),
                                  cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
            except:
                pass

            # Mostrar informaciÃ³n
            cv2.putText(frame, f"Fotos: {captured}/{num_photos}", (10, 30),
                       cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
            cv2.putText(frame, "ESPACIO: Capturar | Q: Salir", (10, 70),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)

            # CÃ­rculo guÃ­a central
            h, w = frame.shape[:2]
            cv2.circle(frame, (w//2, h//2), 150, (0, 255, 255), 2)

            cv2.imshow('Entrenamiento - Captura de Fotos', frame)

            key = cv2.waitKey(1) & 0xFF

            if key == ord(' '):  # Espacio para capturar
                # Guardar foto
                photo_path = PHOTOS_DIR / f"{self.person_name.replace(' ', '_')}_{captured+1}.jpg"
                cv2.imwrite(str(photo_path), frame)
                photo_paths.append(photo_path)
                captured += 1

                # Efecto flash
                flash = np.ones_like(frame) * 255
                cv2.imshow('Entrenamiento - Captura de Fotos', flash)
                cv2.waitKey(100)

                print(f"âœ“ Foto {captured}/{num_photos} capturada")

            elif key == ord('q'):
                break

        cap.release()
        cv2.destroyAllWindows()

        print(f"\nâœ… Captura completada: {captured} fotos guardadas en {PHOTOS_DIR}")
        return photo_paths

    def load_photos_from_directory(self, photo_dir: Path = None) -> List[Path]:
        """
        Carga fotos desde un directorio
        """
        if photo_dir is None:
            photo_dir = PHOTOS_DIR

        extensions = ['.jpg', '.jpeg', '.png', '.bmp']
        photos = []

        for ext in extensions:
            photos.extend(list(photo_dir.glob(f"*{ext}")))
            photos.extend(list(photo_dir.glob(f"*{ext.upper()}")))

        return sorted(photos)

    def extract_embeddings(self, photo_paths: List[Path]) -> None:
        """
        Extrae embeddings de todas las fotos usando DeepFace
        """
        print(f"\nğŸ§  Extrayendo embeddings con modelo {MODEL_NAME}...")
        print(f"   Este modelo es extremadamente robusto contra:")
        print("   âœ“ Cambios de iluminaciÃ³n (dÃ­a/noche, interior/exterior)")
        print("   âœ“ Diferentes Ã¡ngulos de pose (Â±45Â°)")
        print("   âœ“ Expresiones faciales variadas")
        print("   âœ“ Ruido y baja calidad de imagen")
        print("   âœ“ Oclusiones parciales (lentes, gorras, etc.)\n")

        for photo_path in tqdm(photo_paths, desc="Procesando fotos"):
            try:
                # Extraer embedding usando DeepFace
                embedding_objs = DeepFace.represent(
                    img_path=str(photo_path),
                    model_name=MODEL_NAME,
                    detector_backend=DETECTOR_BACKEND,
                    enforce_detection=True,
                    align=True  # Alinear rostro antes de extraer features
                )

                # DeepFace puede detectar mÃºltiples rostros, tomamos el primero
                if embedding_objs:
                    embedding = embedding_objs[0]["embedding"]
                    self.embeddings.append(embedding)
                    self.valid_photos.append(str(photo_path))

            except Exception as e:
                self.failed_photos.append((str(photo_path), str(e)))
                tqdm.write(f"âœ— Error en {photo_path.name}: {str(e)}")

        print(f"\nâœ… Procesamiento completado:")
        print(f"   âœ“ Exitosos: {len(self.valid_photos)}")
        print(f"   âœ— Fallidos: {len(self.failed_photos)}")

    def save_embeddings(self) -> Path:
        """
        Guarda los embeddings en formato JSON compatible con el frontend
        """
        if not self.embeddings:
            raise ValueError("No hay embeddings para guardar")

        # Convertir embeddings a formato serializable
        embeddings_list = [emb if isinstance(emb, list) else emb.tolist()
                          for emb in self.embeddings]

        output_data = {
            "name": self.person_name,
            "model": MODEL_NAME,
            "detector": DETECTOR_BACKEND,
            "embeddings": embeddings_list,
            "embedding_size": len(embeddings_list[0]),
            "num_photos": len(self.valid_photos),
            "timestamp": datetime.now().isoformat(),
            "valid_photos": self.valid_photos,
            "failed_photos": [{"path": p, "error": e} for p, e in self.failed_photos]
        }

        # Guardar archivo principal
        output_file = OUTPUT_DIR / "face_embeddings.json"
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(output_data, f, indent=2, ensure_ascii=False)

        # Guardar backup con timestamp
        backup_file = OUTPUT_DIR / f"face_embeddings_{self.person_name.replace(' ', '_')}_{int(datetime.now().timestamp())}.json"
        with open(backup_file, 'w', encoding='utf-8') as f:
            json.dump(output_data, f, indent=2, ensure_ascii=False)

        print(f"\nğŸ’¾ Embeddings guardados:")
        print(f"   ğŸ“„ Archivo principal: {output_file}")
        print(f"   ğŸ“„ Backup: {backup_file}")

        return output_file

    def compute_statistics(self) -> Dict:
        """
        Calcula estadÃ­sticas de calidad del entrenamiento
        """
        if not self.embeddings:
            return {}

        embeddings_array = np.array(self.embeddings)

        # Calcular similitudes entre embeddings (distancia coseno)
        from scipy.spatial.distance import cosine

        similarities = []
        for i in range(len(embeddings_array)):
            for j in range(i+1, len(embeddings_array)):
                similarity = 1 - cosine(embeddings_array[i], embeddings_array[j])
                similarities.append(similarity)

        stats = {
            "mean_similarity": float(np.mean(similarities)) if similarities else 0,
            "std_similarity": float(np.std(similarities)) if similarities else 0,
            "min_similarity": float(np.min(similarities)) if similarities else 0,
            "max_similarity": float(np.max(similarities)) if similarities else 0,
            "embedding_dimension": len(embeddings_array[0]),
            "num_embeddings": len(embeddings_array)
        }

        print(f"\nğŸ“Š EstadÃ­sticas de Calidad:")
        print(f"   Similitud promedio: {stats['mean_similarity']:.3f} (mÃ¡s cercano a 1.0 es mejor)")
        print(f"   DesviaciÃ³n estÃ¡ndar: {stats['std_similarity']:.3f} (menor es mÃ¡s consistente)")
        print(f"   DimensiÃ³n del embedding: {stats['embedding_dimension']}")
        print(f"   Total de embeddings: {stats['num_embeddings']}")

        if stats['mean_similarity'] > 0.8:
            print("   âœ… Excelente calidad de entrenamiento!")
        elif stats['mean_similarity'] > 0.6:
            print("   âš ï¸  Calidad aceptable, considera capturar mÃ¡s fotos variadas")
        else:
            print("   âŒ Baja calidad, verifica que todas las fotos sean de la misma persona")

        return stats


def main():
    print("="*70)
    print("ğŸ¯ SISTEMA DE ENTRENAMIENTO DE RECONOCIMIENTO FACIAL ROBUSTO")
    print("="*70)
    print(f"\nModelo: {MODEL_NAME}")
    print(f"Detector: {DETECTOR_BACKEND}")
    print(f"DimensiÃ³n del embedding: 512 dimensiones (Facenet512)")
    print("\nCaracterÃ­sticas:")
    print("  âœ“ Resistente a cambios de iluminaciÃ³n extremos")
    print("  âœ“ Funciona con diferentes Ã¡ngulos (Â±45Â°)")
    print("  âœ“ Robusto contra ruido y compresiÃ³n")
    print("  âœ“ Tolera oclusiones parciales")
    print("="*70)

    # Solicitar nombre
    person_name = input("\nğŸ‘¤ Ingresa tu nombre completo: ").strip()
    if not person_name:
        print("âŒ Nombre vacÃ­o. Abortando.")
        return

    trainer = FaceTrainer(person_name)

    # OpciÃ³n de captura
    print("\nğŸ“· Opciones de captura:")
    print("  1. Capturar fotos desde webcam (Recomendado)")
    print("  2. Usar fotos existentes en 'training_photos/'")

    choice = input("\nSelecciona una opciÃ³n (1/2): ").strip()

    if choice == "1":
        num_photos = input("\nÂ¿CuÃ¡ntas fotos deseas capturar? (recomendado: 20-30): ").strip()
        num_photos = int(num_photos) if num_photos.isdigit() else 20

        photo_paths = trainer.capture_from_webcam(num_photos)
    else:
        print(f"\nğŸ“‚ Buscando fotos en {PHOTOS_DIR}...")
        photo_paths = trainer.load_photos_from_directory()

        if not photo_paths:
            print(f"âŒ No se encontraron fotos en {PHOTOS_DIR}")
            print("   Coloca tus fotos (.jpg, .png) en esa carpeta e intenta de nuevo.")
            return

        print(f"âœ“ Encontradas {len(photo_paths)} fotos")

    if not photo_paths:
        print("âŒ No hay fotos para procesar.")
        return

    # Extraer embeddings
    trainer.extract_embeddings(photo_paths)

    if not trainer.embeddings:
        print("\nâŒ No se pudo extraer ningÃºn embedding vÃ¡lido.")
        return

    # Calcular estadÃ­sticas
    trainer.compute_statistics()

    # Guardar embeddings
    output_file = trainer.save_embeddings()

    print("\n" + "="*70)
    print("âœ… ENTRENAMIENTO COMPLETADO EXITOSAMENTE")
    print("="*70)
    print(f"\nğŸ“¦ Archivo de embeddings: {output_file}")
    print(f"\nğŸš€ Siguiente paso:")
    print(f"   1. El archivo '{output_file.name}' estÃ¡ listo para usar")
    print(f"   2. Inicia el servidor: npm run dev")
    print(f"   3. El sistema frontend lo cargarÃ¡ automÃ¡ticamente")
    print("\n" + "="*70)


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nâš ï¸  Proceso interrumpido por el usuario.")
    except Exception as e:
        print(f"\n\nâŒ Error: {e}")
        import traceback
        traceback.print_exc()
